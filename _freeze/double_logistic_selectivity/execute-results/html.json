{
  "hash": "9bd40cc6bc419c36713a09c045653f6f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Double Logistic Selectivity (3-parameter formulation)\"\nsubtitle: \"Parameterization, sensitivity, and prior elicitation via RTMB\"\nlightbox: true\nformat:\n  html:\n    toc: true\n    number-sections: true\nexecute:\n  echo: false\n  message: false\n  warning: false\n---\n\n## Overview\n\nThis notebook documents the 3-parameter double logistic selectivity curve used\nfor prior elicitation in the EBS pollock assessment workflow. The formulation\nallows dome-shaped selectivity, where vulnerability increases with age to a peak\nand then declines. This behavior is motivated by gear avoidance at older ages,\nontogenetic habitat shifts, or differential availability between age classes.\n\n## Model definition\n\nLet age be $a$, with parameters $p_1$, $p_2$, and $p_3$ and derived inflection\npoints $\\gamma_1$ and $\\gamma_2$:\n\n$$\n\\gamma_1 = p_1 + p_2, \\qquad\n\\gamma_2 = 2p_1 + p_2 + p_3.\n$$\n\nThe ascending limb is a standard logistic and the descending limb is\none minus a logistic:\n\n$$\n\\text{asc}(a) = \\frac{1}{1 + \\exp\\left[-\\log(19)\\,\\frac{a - \\gamma_1}{p_1}\\right]},\n$$\n\n$$\n\\text{desc}(a) = 1 - \\frac{1}{1 + \\exp\\left[-\\log(19)\\,\\frac{a - \\gamma_2}{p_3}\\right]}.\n$$\n\nThe full double logistic selectivity is\n\n$$\n\\text{sel}(a) = \\min\\left(1,\\ \\frac{\\text{asc}(a)\\,\\text{desc}(a)}{0.95^2}\\right).\n$$\n\n### Interpretation\n\n- $p_1 > 0$ controls the ascending slope and is the distance from\n  $\\gamma_1$ (50% selectivity) to the 95% point.\n- $p_2$ shifts the ascending limb through $\\gamma_1 = p_1 + p_2$.\n- $p_3 > 0$ controls the descending slope and is the distance from\n  $\\gamma_2$ (50% on the descending limb) to the 5% point.\n- The dome width is $\\gamma_2 - \\gamma_1 = p_1 + p_3$.\n- The factor $0.95^{-2}$ normalizes the curve so that when both limbs are at\n  0.95 the product is near 1 (then capped at 1.0).\n\n## Scenarios\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidyr)\nlibrary(patchwork)\n\ndbl_logistic_sel <- function(age, p1, p2, p3) {\n  gamma1 <- p1 + p2\n  gamma2 <- 2 * p1 + p2 + p3\n\n  asc <- 1 / (1 + exp(-log(19) * (age - gamma1) / p1))\n  desc <- 1 - 1 / (1 + exp(-log(19) * (age - gamma2) / p3))\n\n  sel <- asc * desc * 0.95^(-2)\n  pmin(sel, 1.0)\n}\n\nages <- seq(1, 15, by = 0.1)\n\nscenarios <- tibble(\n  scenario = c(\n    \"Wide dome\",\n    \"Asymmetric\\n(fast rise, slow decline)\",\n    \"Asymmetric\\n(slow rise, fast decline)\",\n    \"Nearly asymptotic\"\n  ),\n  p1 = c(2.0, 0.8, 2.0, 1.5),\n  p2 = c(4.0, 4.0, 3.0, 4.0),\n  p3 = c(2.5, 3.0, 0.8, 8.0)\n) %>%\n  mutate(\n    gamma1 = p1 + p2,\n    gamma2 = 2 * p1 + p2 + p3,\n    dome_width = gamma2 - gamma1\n  )\n\nsel_data <- scenarios %>%\n  rowwise() %>%\n  do({\n    scen <- .\n    tibble(\n      scenario = scen$scenario,\n      age = ages,\n      selectivity = dbl_logistic_sel(ages, scen$p1, scen$p2, scen$p3),\n      p1 = scen$p1,\n      p2 = scen$p2,\n      p3 = scen$p3,\n      gamma1 = scen$gamma1,\n      gamma2 = scen$gamma2\n    )\n  }) %>%\n  ungroup() %>%\n  mutate(\n    label = sprintf(\"%s\\n(p1=%.1f, p2=%.1f, p3=%.1f)\", scenario, p1, p2, p3)\n  )\n```\n:::\n\n\n\n::: {#tbl-dl-scenarios .cell tbl-cap='Scenario parameters and derived inflection points'}\n\n```{.r .cell-code .hidden}\n#| label: tbl-dl-scenarios\n#| tbl-cap: \"Scenario parameters and derived inflection points\"\nknitr::kable(\n  scenarios,\n  digits = 2\n)\n```\n\n::: {.cell-output-display}\n\n\n|scenario                            |  p1| p2|  p3| gamma1| gamma2| dome_width|\n|:-----------------------------------|---:|--:|---:|------:|------:|----------:|\n|Wide dome                           | 2.0|  4| 2.5|    6.0|   10.5|        4.5|\n|Asymmetric\n(fast rise, slow decline) | 0.8|  4| 3.0|    4.8|    8.6|        3.8|\n|Asymmetric\n(slow rise, fast decline) | 2.0|  3| 0.8|    5.0|    7.8|        2.8|\n|Nearly asymptotic                   | 1.5|  4| 8.0|    5.5|   15.0|        9.5|\n\n\n:::\n:::\n\n\nThe scenario summary in @tbl-dl-scenarios lists the four parameter sets and the\nderived inflection points ($\\gamma_1$, $\\gamma_2$) used in the selectivity\nscenarios.\n\n## Faceted scenario curves\n\nEach scenario appears on its own panel in @fig-dl-faceted so the ascent,\ndescent, and dome width can be compared against the 50% and 95% reference\nlines.\n\n\n::: {#cell-fig-dl-faceted .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-dl-faceted\n#| fig-cap: \"Double logistic selectivity for each parameter scenario.\"\np1_plot <- ggplot(sel_data, aes(x = age, y = selectivity)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  geom_hline(yintercept = c(0.5, 0.95), linetype = \"dashed\",\n             color = \"gray50\", alpha = 0.7) +\n  geom_vline(aes(xintercept = gamma1), linetype = \"dotted\",\n             color = \"red\", alpha = 0.5) +\n  geom_vline(aes(xintercept = gamma2), linetype = \"dotted\",\n             color = \"orange\", alpha = 0.5) +\n  facet_wrap(~label, ncol = 2) +\n  scale_x_continuous(breaks = seq(2, 14, by = 2)) +\n  scale_y_continuous(limits = c(0, 1.05), breaks = seq(0, 1, by = 0.25)) +\n  labs(\n    title = \"3-parameter double logistic selectivity curves\",\n    subtitle = \"Dashed lines show 50% and 95% selectivity\",\n    x = \"Age\",\n    y = \"Selectivity\",\n    caption = \"Red dotted = gamma1, orange dotted = gamma2\"\n  ) +\n  theme_bw(base_size = 11) +\n  theme(\n    strip.text = element_text(size = 9),\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\np1_plot\n```\n\n::: {.cell-output-display}\n![Double logistic selectivity for each parameter scenario.](double_logistic_selectivity_files/figure-html/fig-dl-faceted-1.png){#fig-dl-faceted width=672}\n:::\n:::\n\n\n## Overlay comparison\n\nAll scenarios are overlaid in @fig-dl-overlay to highlight differences in peak\nage and decline shape when the curves are viewed on a common axis.\n\n\n::: {#cell-fig-dl-overlay .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-dl-overlay\n#| fig-cap: \"All scenarios overlaid for direct comparison.\"\np2_plot <- ggplot(sel_data, aes(x = age, y = selectivity, color = scenario)) +\n  geom_line(linewidth = 1.2) +\n  geom_hline(yintercept = c(0.5, 0.95), linetype = \"dashed\",\n             color = \"gray50\", alpha = 0.5) +\n  scale_x_continuous(breaks = seq(2, 14, by = 2)) +\n  scale_y_continuous(limits = c(0, 1.05), breaks = seq(0, 1, by = 0.25)) +\n  scale_color_brewer(palette = \"Set1\", name = \"Scenario\") +\n  labs(\n    title = \"Comparison of double logistic selectivity curves\",\n    subtitle = \"All scenarios overlaid\",\n    x = \"Age\",\n    y = \"Selectivity\"\n  ) +\n  theme_bw(base_size = 12) +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\np2_plot\n```\n\n::: {.cell-output-display}\n![All scenarios overlaid for direct comparison.](double_logistic_selectivity_files/figure-html/fig-dl-overlay-1.png){#fig-dl-overlay width=672}\n:::\n:::\n\n\n## Parameter sensitivity analysis\n\nThe three panels in @fig-dl-sensitivity show how each parameter changes the\ncurve when the other two are held fixed.\n\n\n::: {#cell-fig-dl-sensitivity .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-dl-sensitivity\n#| fig-cap: \"Sensitivity to p1, p2, and p3 with other parameters fixed.\"\n#| fig-width: 8\n#| fig-height: 8\np1_vary <- expand_grid(\n  p1 = seq(0.5, 3, by = 0.5),\n  p2 = 5,\n  p3 = 2,\n  age = ages\n) %>%\n  rowwise() %>%\n  mutate(selectivity = dbl_logistic_sel(age, p1, p2, p3)) %>%\n  ungroup()\n\np3a <- ggplot(p1_vary, aes(x = age, y = selectivity, color = factor(p1))) +\n  geom_line(linewidth = 1) +\n  scale_color_viridis_d(name = \"p1\", option = \"C\") +\n  scale_y_continuous(limits = c(0, 1.05)) +\n  labs(title = \"Sensitivity to p1 (ascending slope)\",\n       subtitle = \"p2 = 5, p3 = 2 fixed\",\n       x = \"Age\", y = \"Selectivity\") +\n  theme_bw(base_size = 9) +\n  theme(legend.position = \"right\", aspect.ratio = 1)\n\np2_vary <- expand_grid(\n  p1 = 1.5,\n  p2 = seq(2, 8, by = 1),\n  p3 = 2,\n  age = ages\n) %>%\n  rowwise() %>%\n  mutate(selectivity = dbl_logistic_sel(age, p1, p2, p3)) %>%\n  ungroup()\n\np3b <- ggplot(p2_vary, aes(x = age, y = selectivity, color = factor(p2))) +\n  geom_line(linewidth = 1) +\n  scale_color_viridis_d(name = \"p2\", option = \"D\") +\n  scale_y_continuous(limits = c(0, 1.05)) +\n  labs(title = \"Sensitivity to p2 (horizontal shift)\",\n       subtitle = \"p1 = 1.5, p3 = 2 fixed\",\n       x = \"Age\", y = \"Selectivity\") +\n  theme_bw(base_size = 9) +\n  theme(legend.position = \"right\", aspect.ratio = 1)\n\np3_vary <- expand_grid(\n  p1 = 1.5,\n  p2 = 4,\n  p3 = seq(0.5, 6.5, by = 1),\n  age = ages\n) %>%\n  rowwise() %>%\n  mutate(selectivity = dbl_logistic_sel(age, p1, p2, p3)) %>%\n  ungroup()\n\np3c <- ggplot(p3_vary, aes(x = age, y = selectivity, color = factor(p3))) +\n  geom_line(linewidth = 1) +\n  scale_color_viridis_d(name = \"p3\", option = \"E\") +\n  scale_y_continuous(limits = c(0, 1.05)) +\n  labs(title = \"Sensitivity to p3 (descending slope)\",\n       subtitle = \"p1 = 1.5, p2 = 4 fixed\",\n       x = \"Age\", y = \"Selectivity\") +\n  theme_bw(base_size = 9) +\n  theme(legend.position = \"right\", aspect.ratio = 1)\n\np_sensitivity <- (p3a | p3b) / (p3c | plot_spacer()) +\n  plot_annotation(\n    title = \"Parameter sensitivity analysis\",\n    subtitle = \"Effect of varying each parameter individually\"\n  )\n\np_sensitivity\n```\n\n::: {.cell-output-display}\n![Sensitivity to p1, p2, and p3 with other parameters fixed.](double_logistic_selectivity_files/figure-html/fig-dl-sensitivity-1.png){#fig-dl-sensitivity width=768}\n:::\n:::\n\n\n## RTMB implementation with priors\n\nA common approach is to estimate on the log scale for the positive parameters\nand apply lognormal priors on $p_1$ and $p_3$:\n\n$$\n\\log(p_k) \\sim \\mathcal{N}(\\mu_k, \\sigma_k^2), \\qquad k \\in \\{1, 3\\}.\n$$\n\nIf using a lognormal prior specified by median $m$ and coefficient of variation\n$\\text{CV}$ on the natural scale, a convenient conversion is\n\n$$\n\\mu = \\log(m), \\qquad \\sigma = \\sqrt{\\log(\\text{CV}^2 + 1)}.\n$$\n\nParameter $p_2$ can remain unconstrained (normal prior) or be modeled on the log\nscale if you want to enforce $p_2 > 0$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| eval: true\n#| echo: true\nlibrary(RTMB)\n\ndbl_logistic_sel <- function(age, p1, p2, p3) {\n  gamma1 <- p1 + p2\n  gamma2 <- 2 * p1 + p2 + p3\n  asc <- 1 / (1 + exp(-log(19) * (age - gamma1) / p1))\n  desc <- 1 - 1 / (1 + exp(-log(19) * (age - gamma2) / p3))\n  (asc * desc * 0.95^(-2))\n}\n\nlognorm_from_median_cv <- function(median, cv) {\n  sigma <- sqrt(log(cv^2 + 1))\n  mu <- log(median)\n  list(mu = mu, sigma = sigma)\n}\n\nage <- seq(1, 15, by = 0.25)\nsel_obs <- c(\n  0, 0, 0, 0, 0, 0, 0, 0.01, 0.01, 0.037142857, 0.064285714, 0.091428571,\n  0.118571429, 0.145714286, 0.172857143, 0.2, 0.205882353, 0.211764706,\n  0.217647059, 0.223529412, 0.229411765, 0.235294118, 0.241176471,\n  0.247058824, 0.252941176, 0.258823529, 0.264705882, 0.270588235,\n  0.276470588, 0.282352941, 0.288235294, 0.294117647, 0.3, 0.31, 0.32,\n  0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43,\n  0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.5125, 0.525, 0.5375, 0.55,\n  0.5625, 0.575, 0.5875, 0.6, 0.6125, 0.625, 0.6375, 0.65, 0.6625,\n  0.675, 0.6875, 0.7, 0.7125, 0.725, 0.7375, 0.75, 0.7625, 0.775,\n  0.7875, 0.8, 0.807894737, 0.815789474, 0.823684211, 0.831578947,\n  0.839473684, 0.847368421, 0.855263158, 0.863157895, 0.871052632,\n  0.878947368, 0.886842105, 0.894736842, 0.902631579, 0.910526316,\n  0.918421053, 0.926315789, 0.934210526, 0.942105263, 0.95, 0.954545455,\n  0.959090909, 0.963636364, 0.968181818, 0.972727273, 0.977272727,\n  0.981818182, 0.986363636, 0.990909091, 0.995454545, 1, 1, 1, 1, 1, 1,\n  1, 0.989285714, 0.978571429, 0.967857143, 0.957142857, 0.946428571,\n  0.935714286, 0.925, 0.914285714, 0.903571429, 0.892857143, 0.882142857,\n  0.871428571, 0.860714286, 0.85, 0.839285714, 0.828571429, 0.817857143,\n  0.807142857, 0.796428571, 0.785714286, 0.775, 0.764285714, 0.753571429,\n  0.742857143, 0.732142857, 0.721428571, 0.710714286, 0.7\n)\nsel_sd <- rep(0.05, length(age))\n\np1_prior <- lognorm_from_median_cv(median = 1.5, cv = 0.4)\np3_prior <- lognorm_from_median_cv(median = 2.5, cv = 0.6)\np2_prior <- list(mu = 4, sigma = 1)\n\nmake_prior_data <- function(p1_prior, p2_prior, p3_prior) {\n  list(\n    age = age,\n    sel_obs = sel_obs,\n    sel_sd = sel_sd,\n    mu_log_p1 = p1_prior$mu,\n    sd_log_p1 = p1_prior$sigma,\n    mu_p2 = p2_prior$mu,\n    sd_p2 = p2_prior$sigma,\n    mu_log_p3 = p3_prior$mu,\n    sd_log_p3 = p3_prior$sigma\n  )\n}\n\ndata <- make_prior_data(p1_prior, p2_prior, p3_prior)\n\nparameters <- list(\n  log_p1 = log(1.5),\n  p2 = 4,\n  log_p3 = log(2.5)\n)\n\nmake_obj <- function(data, parameters) {\n  f <- function(parms) {\n    getAll(data, parms, warn = FALSE)\n    p1 <- exp(log_p1)\n    p3 <- exp(log_p3)\n    sel_hat <- dbl_logistic_sel(age, p1, p2, p3)\n\n    nll <- 0\n    nll <- nll - dnorm(log_p1, mu_log_p1, sd_log_p1, log = TRUE)\n    nll <- nll - dnorm(p2, mu_p2, sd_p2, log = TRUE)\n    nll <- nll - dnorm(log_p3, mu_log_p3, sd_log_p3, log = TRUE)\n\n    ADREPORT(c(p1 = p1, p2 = p2, p3 = p3))\n    nll\n  }\n\n  MakeADFun(f, parameters)\n}\n\nobj <- make_obj(data, parameters)\nopt <- nlminb(obj$par, obj$fn, obj$gr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nouter mgc:  0 \n```\n\n\n:::\n\n```{.r .cell-code}\n#| eval: true\n#| echo: true\nsdrep <- sdreport(obj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nouter mgc:  0 \nouter mgc:  0.006737636 \nouter mgc:  0.006737636 \nouter mgc:  0.001 \nouter mgc:  0.001 \nouter mgc:  0.003252194 \nouter mgc:  0.003252194 \nouter mgc:  2.5 \n```\n\n\n:::\n:::\n\n\n## MCMC evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| eval: true\n#| echo: true\nlibrary(SparseNUTS)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: StanEstimators\n```\n\n\n:::\n\n```{.r .cell-code}\n#| eval: true\n#| echo: true\nrun_snuts <- function(obj, data, seed = 1, model_name = \"selectivity\") {\n  sample_snuts(\n    obj,\n    refresh = 0,\n    seed = seed,\n    model_name = model_name,\n    cores = 1,\n    chains = 1,\n    num_samples = 1150,\n    num_warmup = 150,\n    globals = list(dat = data)\n  )\n}\n\nfit_set1 <- run_snuts(obj, data, seed = 1, model_name = \"selectivity_set1\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nOptimizing...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRebuilding RTMB obj without random effects...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\ndiag metric selected b/c low correlations (max=0)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nlog-posterior at inits=(-1.21); at conditional mode=-1.213\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStarting MCMC sampling...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nGradient evaluation took 3.4e-05 seconds\n1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds.\nAdjust your expectations accordingly!\n\n\n\n Elapsed Time: 0.018 seconds (Warm-up)\n               0.197 seconds (Sampling)\n               0.215 seconds (Total)\n\n\n\nModel 'selectivity_set1' has 3 pars, and was fit using NUTS with a 'diag' metric\n1 chain(s) of 1300 total iterations (150 warmup) were used\nAverage run time per chain was 0.22 seconds \nMinimum ESS=360.7 (31.37%), and maximum Rhat=1.015\nThere were 0 divergences after warmup\n```\n\n\n:::\n:::\n\n\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\n#| include: false\nmcmc_selectivity_df <- function(fit, age) {\n  p1 <- exp(fit$samples[, , 1])\n  p2 <- fit$samples[, , 2]\n  p3 <- exp(fit$samples[, , 3])\n\n  tibble(p1, p2, p3) %>%\n    mutate(set = factor(row_number())) %>%\n    crossing(age = age) %>%\n    mutate(sel = dbl_logistic_sel(age, p1, p2, p3)) %>%\n    mutate(age = as.numeric(age)) %>%\n    arrange(set, age)\n}\n\nplot_mcmc_selectivity <- function(df, alpha = 0.1) {\n  ggplot(df, aes(age, sel, group = set)) +\n    geom_line(alpha = alpha) +\n    ggthemes::theme_few()\n}\n```\n:::\n\n\n\n::: {#cell-fig-dl-marginals .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-dl-marginals\n#| fig-cap: \"Marginal posterior distributions for selectivity parameters (SparseNUTS, prior set 1).\"\nSparseNUTS::plot_marginals(fit_set1, pars = 1:3)\n```\n\n::: {.cell-output-display}\n![Marginal posterior distributions for selectivity parameters (SparseNUTS, prior set 1).](double_logistic_selectivity_files/figure-html/fig-dl-marginals-1.png){#fig-dl-marginals width=672}\n:::\n:::\n\n\nThe marginal posterior densities in @fig-dl-marginals summarize $(p_1, p_2,\np_3)$ under prior set 1.\n\n\n::: {#cell-fig-dl-pairs .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-dl-pairs\n#| fig-cap: \"Pairwise posterior scatterplots for selectivity parameters.\"\npairs(fit_set1)\n```\n\n::: {.cell-output-display}\n![Pairwise posterior scatterplots for selectivity parameters.](double_logistic_selectivity_files/figure-html/fig-dl-pairs-1.png){#fig-dl-pairs width=672}\n:::\n:::\n\n\n\n::: {#cell-fig-dl-mcmc-set1 .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-dl-mcmc-set1\n#| fig-cap: \"MCMC selectivity draws for prior set 1 (p1 median 1.5, p3 median 2.5, p2 sd 1).\"\ndf_set1 <- mcmc_selectivity_df(fit_set1, age)\nplot_mcmc_selectivity(df_set1)\n```\n\n::: {.cell-output-display}\n![MCMC selectivity draws for prior set 1 (p1 median 1.5, p3 median 2.5, p2 sd 1).](double_logistic_selectivity_files/figure-html/fig-dl-mcmc-set1-1.png){#fig-dl-mcmc-set1 width=672}\n:::\n:::\n\n\n### Additional prior sets\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\np1_prior_set2 <- lognorm_from_median_cv(median = 1.5, cv = 0.4)\np3_prior_set2 <- lognorm_from_median_cv(median = 8, cv = 0.6)\np2_prior_set2 <- list(mu = 4, sigma = 1)\ndata_set2 <- make_prior_data(p1_prior_set2, p2_prior_set2, p3_prior_set2)\nobj_set2 <- make_obj(data_set2, parameters)\nfit_set2 <- run_snuts(obj_set2, data_set2, seed = 2, model_name = \"selectivity_set2\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nOptimizing...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRebuilding RTMB obj without random effects...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\ndiag metric selected b/c low correlations (max=0)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nlog-posterior at inits=(-1.21); at conditional mode=-1.213\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStarting MCMC sampling...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nGradient evaluation took 2.8e-05 seconds\n1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.\nAdjust your expectations accordingly!\n\n\n\n Elapsed Time: 0.018 seconds (Warm-up)\n               0.116 seconds (Sampling)\n               0.134 seconds (Total)\n\n\n\nModel 'selectivity_set2' has 3 pars, and was fit using NUTS with a 'diag' metric\n1 chain(s) of 1300 total iterations (150 warmup) were used\nAverage run time per chain was 0.13 seconds \nMinimum ESS=393.8 (34.24%), and maximum Rhat=1.003\nThere were 0 divergences after warmup\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\np1_prior_set3 <- lognorm_from_median_cv(median = 1.5, cv = 0.4)\np3_prior_set3 <- lognorm_from_median_cv(median = 8, cv = 0.6)\np2_prior_set3 <- list(mu = 4, sigma = 2)\ndata_set3 <- make_prior_data(p1_prior_set3, p2_prior_set3, p3_prior_set3)\nobj_set3 <- make_obj(data_set3, parameters)\nfit_set3 <- run_snuts(obj_set3, data_set3, seed = 3, model_name = \"selectivity_set3\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nOptimizing...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRebuilding RTMB obj without random effects...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\ndiag metric selected b/c low correlations (max=0)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nlog-posterior at inits=(-1.91); at conditional mode=-1.906\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStarting MCMC sampling...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nGradient evaluation took 2.2e-05 seconds\n1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nAdjust your expectations accordingly!\n\n\n\n Elapsed Time: 0.017 seconds (Warm-up)\n               0.121 seconds (Sampling)\n               0.138 seconds (Total)\n\n\n\nModel 'selectivity_set3' has 3 pars, and was fit using NUTS with a 'diag' metric\n1 chain(s) of 1300 total iterations (150 warmup) were used\nAverage run time per chain was 0.14 seconds \nMinimum ESS=427 (37.13%), and maximum Rhat=1.005\nThere were 0 divergences after warmup\n```\n\n\n:::\n:::\n\n\n\n::: {#cell-fig-dl-mcmc-set2 .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-dl-mcmc-set2\n#| fig-cap: \"MCMC selectivity draws for prior set 2 (p1 median 1.5, p3 median 8, p2 sd 1).\"\ndf_set2 <- mcmc_selectivity_df(fit_set2, age)\nplot_mcmc_selectivity(df_set2)\n```\n\n::: {.cell-output-display}\n![MCMC selectivity draws for prior set 2 (p1 median 1.5, p3 median 8, p2 sd 1).](double_logistic_selectivity_files/figure-html/fig-dl-mcmc-set2-1.png){#fig-dl-mcmc-set2 width=672}\n:::\n:::\n\n\n\n::: {#cell-fig-dl-mcmc-set3 .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-dl-mcmc-set3\n#| fig-cap: \"MCMC selectivity draws for prior set 3 (p1 median 1.5, p3 median 8, p2 sd 2).\"\ndf_set3 <- mcmc_selectivity_df(fit_set3, age)\nplot_mcmc_selectivity(df_set3)\n```\n\n::: {.cell-output-display}\n![MCMC selectivity draws for prior set 3 (p1 median 1.5, p3 median 8, p2 sd 2).](double_logistic_selectivity_files/figure-html/fig-dl-mcmc-set3-1.png){#fig-dl-mcmc-set3 width=672}\n:::\n:::\n\n",
    "supporting": [
      "double_logistic_selectivity_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}